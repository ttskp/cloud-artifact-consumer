AWSTemplateFormatVersion: '2010-09-09'

Description: Consumer side of CFN Artifact Distribution.

Parameters:

  DistributionTopic:
    Type: String
    Description: The distributor topic announcing new files to copy.
    Default: "arn:aws:sns:eu-west-1:529985782713:build-artifact-distributor-DistributionTopic-1A5L07HYRFVRA"

  DistributionRegion:
    Type: String
    Description: The region where the distributor is located.
    Default: "eu-west-1"

  DistributionBucket:
    Type: String
    Description: The source bucket of the distribution
    Default: tts-cloud-artifacts-529985782713-eu-west-1

  InitialDistributionRole:
    Type: String
    Description: A role in the distributor account to assume for triggering the initset distribution.
    Default: "arn:aws:iam::529985782713:role/TriggerInitSetRole"

  InitialDistributionSetMachine:
    Type: String
    Description: State machine to trigger for distributing the initset.
    Default: "arn:aws:states:eu-west-1:529985782713:stateMachine:InitSetRetrieverMachine-i1BYUlZbD1Si"

  TargetBucket:
    Type: String
    Default: ""
    Description: |
      Name of an existing bucket in the target account to specify as the bucket to copy the artifacts to.
      If the parameter is left empty, a new bucket with the name tts-cloud-artifacts-${AWS::AccountId}-${AWS::Region}
      is created and used as the target bucket.

  TriggerVersion:
    Type: String
    Default: 1.0
    Description: Use a different value during stack update to trigger copying the initial set.

Conditions:
  CreateNewBucket: !Equals [ !Ref TargetBucket, "" ]

Resources:

  ArtifactsBucket:
    Type: AWS::S3::Bucket
    Condition: CreateNewBucket
    DeletionPolicy: Retain
    Properties:
      BucketName: !Sub "tts-cloud-artifacts-${AWS::AccountId}-${AWS::Region}"

  CopyFunction:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: !Sub |
          import json
          import os

          import boto3
          from botocore.vendored import requests


          def handler(event, context):
              print(event)

              for record in event["Records"]:
                  print(record["body"])
                  body = json.loads(record["body"])
                  presigned_url = body["ArtifactUrl"]

                  file_name = body["ArtifactKey"]
                  try:
                      file_data = download_file_data(presigned_url)

                      if is_template(file_name, file_data):
                          file_data = replace_bucket_name_in_template(file_data)

                      upload_file_to_bucket(file_data, file_name)
                  except IOError as e:
                      # TODO: Should this be connected to an alarm or a topic?
                      print(f"File {file_name} could not be downloaded.")
                      print(e)


          def download_file_data(presigned_url):
              requested_object_as_stream = requests.get(presigned_url, stream=True)
              if int(requested_object_as_stream.status_code) >= 400:
                  raise IOError(f"Status: {requested_object_as_stream.status_code}, "
                                f"{requested_object_as_stream.content.decode('utf-8')}")

              return requested_object_as_stream.content


          def upload_file_to_bucket(file_data, s3_filename):
              artifacts_bucket_name = os.environ["ARTIFACTS_BUCKET"]
              s3 = boto3.client('s3')
              s3.put_object(Bucket=artifacts_bucket_name, Key=s3_filename, Body=file_data)


          def replace_bucket_name_in_template(file_data):
              target_bucket = os.environ["ARTIFACTS_BUCKET"]
              distributor_bucket = os.environ["DISTRIBUTOR_BUCKET"]
              return file_data \
                  .replace(b"S3Bucket: %b" % distributor_bucket.encode(),
                           b"S3Bucket: %b" % target_bucket.encode()) \
                  .replace(b"s3://%b" % distributor_bucket.encode(),
                           b"s3://%b" % target_bucket.encode()) \
                  .replace(b"https://%b" % distributor_bucket.encode(),
                           b"https://%b" % target_bucket.encode()) \
                  .replace(b"Default: %b" % distributor_bucket.encode(),
                           b"Default: %b" % target_bucket.encode())


          def is_template(file_name, file_data):
              return is_yaml_file(file_name) and has_template_header(file_data)


          def is_yaml_file(file_name):
              return file_name.endswith(".yaml") or file_name.endswith(".yml")


          def has_template_header(file_data):
              file_content = file_data.decode("utf-8")
              return file_content.startswith("AWSTemplateFormatVersion")

      Timeout: 300
      MemorySize: 512
      Role: !GetAtt CopyRole.Arn
      Handler: index.handler
      Runtime: python3.6
      Environment:
        Variables:
          ARTIFACTS_BUCKET: !If [CreateNewBucket, !Ref ArtifactsBucket, !Ref TargetBucket]
          DISTRIBUTOR_BUCKET: !Ref DistributionBucket

  CopyRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: allowLambdaLogs
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - logs:*
                Resource: arn:aws:logs:*:*:*
        - PolicyName: allowSqs
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - sqs:ReceiveMessage
                  - sqs:DeleteMessage
                  - sqs:GetQueueAttributes
                  - sqs:ChangeMessageVisibility
                Resource: !GetAtt Queue.Arn
        - PolicyName: allowPutObject
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:PutObject
                Resource: !If [CreateNewBucket, !Sub "${ArtifactsBucket.Arn}/*", !Sub "arn:aws:s3:::TargetBucket"]

  QueueToCopyFunctionMapping:
    Type: AWS::Lambda::EventSourceMapping
    Properties:
      Enabled: true
      EventSourceArn: !GetAtt Queue.Arn
      FunctionName: !Ref CopyFunction

  Queue:
    Type: AWS::SQS::Queue
    Properties:
      VisibilityTimeout: 300

  QueueSubscription:
    Type: AWS::SNS::Subscription
    Properties:
      TopicArn: !Ref DistributionTopic
      Protocol: sqs
      Endpoint: !GetAtt Queue.Arn
      Region: !Ref DistributionRegion
      RawMessageDelivery: true
      FilterPolicy:
        account: ["ALL", !Sub "${AWS::AccountId}"]
        region: ["ALL", !Sub "${AWS::Region}"]

  ConsumerQueuePolicy:
    Type: AWS::SQS::QueuePolicy
    Properties:
      Queues:
        - !Ref Queue
      PolicyDocument:
        Id: "DistributorTopicPolicy"
        Version: "2012-10-17"
        Statement:
          - Effect: "Allow"
            Principal: "*"
            Action: "sqs:SendMessage"
            Resource: "*"
            Condition:
              ArnEquals:
                "aws:SourceArn": !Ref DistributionTopic

  InitialSetTrigger:
    Type: Custom::InitialSetTrigger
    Properties:
      ServiceToken: !GetAtt InitialSetTriggerFunction.Arn
      Version: !Ref TriggerVersion
    DependsOn: Queue

  InitialSetTriggerFunction:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: !Sub |
          import json
          import os
          import traceback

          import boto3
          import cfnresponse


          def handler(event, context):
              if "RequestType" in event and "Delete" == event["RequestType"]:
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, {})
                  return

              print(event)
              try:
                  cross_account_role = os.environ["INITIAL_DISTRIBUTION_ROLE"]
                  distribution_account_credentials = get_cross_account_credentials(cross_account_role)
                  step_functions = distribution_account_sfn_client(distribution_account_credentials)

                  init_set_machine_arn = os.environ["INITIAL_DISTRIBUTION_MACHINE"]
                  account_id = os.environ["CONSUMER_ACCOUNT_ID"]
                  region = os.environ["CONSUMER_REGION"]

                  response = step_functions.start_execution(
                      stateMachineArn=init_set_machine_arn,
                      input=json.dumps({
                          "AccountId": account_id,
                          "Region": region
                      })
                  )

                  print(response)

                  cfnresponse.send(event, context, cfnresponse.SUCCESS, {"StepFunctionExecution": str(response)})
              except Exception as e:
                  print(traceback.format_exc())
                  cfnresponse.send(
                      event, context, cfnresponse.FAILED,
                      {"Message": "An exception of type {0} occurred. Arguments:\n{1!r}".format(type(e).__name__, e.args)}
                  )


          def distribution_account_sfn_client(distribution_account_credentials):
              aws_access_key_id = distribution_account_credentials["AccessKeyId"]
              aws_secret_access_key = distribution_account_credentials["SecretAccessKey"]
              aws_session_token = distribution_account_credentials["SessionToken"]

              distributor_region = os.environ["INITIAL_DISTRIBUTION_REGION"]

              return boto3.client("stepfunctions",
                                  region_name=distributor_region,
                                  aws_access_key_id=aws_access_key_id,
                                  aws_secret_access_key=aws_secret_access_key,
                                  aws_session_token=aws_session_token)


          def get_cross_account_credentials(cross_account_role):
              sts = boto3.client("sts")
              sts_response = sts.assume_role(
                  RoleArn=cross_account_role,
                  RoleSessionName="AssumeCrossAccountRole",
                  DurationSeconds=900)
              return sts_response["Credentials"]

      Handler: index.handler
      Timeout: 3
      Role: !GetAtt InitialSetTriggerRole.Arn
      Runtime: python3.6
      Environment:
        Variables:
          INITIAL_DISTRIBUTION_MACHINE: !Ref InitialDistributionSetMachine
          INITIAL_DISTRIBUTION_ROLE: !Ref InitialDistributionRole
          INITIAL_DISTRIBUTION_REGION: !Ref DistributionRegion
          CONSUMER_ACCOUNT_ID: !Sub "${AWS::AccountId}"
          CONSUMER_REGION: !Sub "${AWS::Region}"

  InitialSetTriggerRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action: sts:AssumeRole
            Principal:
              Service:
                - lambda.amazonaws.com
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: Invoke-Init-Set-Distribution
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              Effect: Allow
              Action: sts:AssumeRole
              Resource: arn:aws:iam::529985782713:role/TriggerInitSetRole
